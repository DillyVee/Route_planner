# DRPP Complete Pipeline Guide

## Overview

This guide covers the **complete DRPP visualization and solving pipeline** with all recent improvements:

1. **V4 Performance Optimization** - On-demand routing for large datasets
2. **Complete Pipeline** - From KML to rich visualizations
3. **Multiple Algorithms** - RFCS, V4 Greedy, Legacy Greedy, Hungarian
4. **Rich Visualizations** - Interactive HTML maps with segment IDs and route steps

---

## Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements_production.txt
```

### 2. Run the Pipeline

```bash
python run_drpp_pipeline.py your_segments.kml v4
```

This will:
- Parse your KML file
- Extract segment IDs and directionality
- Build directed graph
- Solve DRPP using V4 greedy algorithm
- Generate visualizations (HTML, GeoJSON, SVG)

### 3. View Results

Open `output/route_map.html` in your browser to see:
- Every segment color-coded by requirement type
- Segment ID labels on all segments
- Route step numbering (1, 2, 3...)
- Interactive map you can zoom/pan

---

## What's New

### âœ… V4 Performance Optimization (MAJOR)

**Problem**: V4 greedy was taking forever for large datasets (11,060+ segments) because it precomputed ALL-PAIRS shortest paths.

**Solution**: New on-demand routing mode that computes distances as needed.

**Performance Improvement**:
- **Before**: 11,060 Ã— 11,060 = 122M distance computations (very slow)
- **After**: ~11,060 single-source Dijkstra calls (much faster)
- **Speedup**: 10-100x faster for large datasets

**How it Works**:
1. Auto-detects when cluster has >1000 segment endpoints
2. Switches to on-demand mode automatically
3. Computes distances only as needed (not all pairs)
4. Each iteration: ONE Dijkstra from current position

**Code Changes**:
- `drpp_core/greedy_router.py`:
  - Added `use_ondemand` parameter
  - Added `_greedy_route_ondemand()` function
  - Auto-switches for large clusters (>1000 endpoints)

**Usage**:
```python
from drpp_core import greedy_route_cluster

result = greedy_route_cluster(
    graph=graph,
    required_edges=edges,
    segment_indices=segment_list,
    start_node=start,
    use_ondemand=True  # Enable on-demand mode
)
```

---

### âœ… Complete Pipeline Implementation

**New Files**:
- `drpp_pipeline.py` - Main pipeline orchestrator
- `drpp_visualization.py` - Visualization module (already existed, now integrated)
- `run_drpp_pipeline.py` - Simple command-line script

**Pipeline Phases**:

1. **Parse KML** - Extract segments, IDs, directionality
2. **Build Graph** - Create directed graph from segments
3. **Solve DRPP** - Use selected algorithm (RFCS/V4/Greedy/Hungarian)
4. **Generate Visualizations** - Create HTML/GeoJSON/SVG outputs
5. **Statistics** - Compute route metrics

**Code Example**:
```python
from pathlib import Path
from drpp_pipeline import DRPPPipeline

pipeline = DRPPPipeline()

results = pipeline.run(
    kml_file=Path('your_file.kml'),
    algorithm='v4',  # or 'rfcs', 'greedy', 'hungarian'
    output_dir=Path('./output'),
    output_formats=['html', 'geojson', 'svg']
)

print(f"Total distance: {results['total_distance'] / 1000:.1f} km")
print(f"Coverage: {results['coverage']:.1f}%")
```

---

### âœ… Rich Visualizations

**Features**:
- âœ… Color-coded segments by requirement type:
  - Red: Forward required â†’
  - Blue: Backward required â†
  - Purple: Both directions required â†”
  - Gray: Not required
  - Orange: Deadhead (routing between segments)
- âœ… Segment ID labels on every segment
- âœ… Route step numbering (1, 2, 3...)
- âœ… Interactive HTML map (zoom, pan, layers)
- âœ… Multiple output formats (HTML, GeoJSON, SVG)

**Output Formats**:

1. **HTML** (`route_map.html`)
   - Interactive Folium/Leaflet map
   - Layer control (toggle segments/route)
   - Click segments for details
   - Legend with color meanings

2. **GeoJSON** (`route_data.geojson`)
   - Machine-readable format
   - Import into GIS software
   - All properties preserved

3. **SVG** (`route_map.svg`)
   - Static vector image
   - Scalable graphics
   - Embed in documents

**Customization**:
```python
from drpp_visualization import VisualizationConfig

config = VisualizationConfig(
    colors={
        'forward_required': '#FF0000',
        'backward_required': '#0000FF',
        'both_required': '#9900FF',
        'not_required': '#CCCCCC',
        'deadhead': '#FFA500'
    },
    segment_label_size=10,
    step_label_size=12,
    show_segment_ids=True,
    show_step_numbers=True
)

results = pipeline.run(
    kml_file=kml_file,
    visualization_config=config.__dict__
)
```

---

## Algorithm Comparison

| Algorithm | Speed | Quality | Memory | Best For |
|-----------|-------|---------|--------|----------|
| **V4 Greedy** | âš¡âš¡âš¡ Very Fast | â­â­ Good | ğŸ’¾ Low | Large datasets (>1000 segments) |
| **RFCS** | âš¡ Moderate | â­â­â­ Excellent | ğŸ’¾ğŸ’¾ Medium | High-quality routes needed |
| **Legacy Greedy** | âš¡âš¡ Fast | â­â­ Good | ğŸ’¾ Low | Medium datasets |
| **Hungarian** | âš¡ Slow | â­â­â­ Excellent | ğŸ’¾ğŸ’¾ Medium | Small datasets (<500 segments) |

### When to Use Each Algorithm

**V4 Greedy** (Recommended for most cases):
- âœ… Large datasets (1000+ segments)
- âœ… Need fast results
- âœ… Acceptable route quality
- âœ… Auto-enables on-demand mode for huge datasets

**RFCS** (Best quality):
- âœ… Need highest quality routes
- âœ… Moderate dataset size
- âœ… Can afford longer computation time

**Legacy Greedy**:
- âœ… Compatibility with older systems
- âœ… Medium datasets

**Hungarian**:
- âœ… Small datasets (<500 segments)
- âœ… Need exact optimization

---

## KML Format Requirements

Your KML file should contain LineString placemarks with:

### Required:
- `<coordinates>` - Segment coordinates (lon,lat format)

### Optional but Recommended:
- `<name>` - Segment ID (auto-generated if missing)
- `<ExtendedData>` - Metadata:
  - `oneway` - One-way flag (yes/no/true/false)
  - `maxspeed` - Speed limit
  - Other metadata preserved

### Example KML:
```xml
<?xml version="1.0" encoding="UTF-8"?>
<kml xmlns="http://www.opengis.net/kml/2.2">
  <Document>
    <Placemark>
      <name>Main_St_001</name>
      <LineString>
        <coordinates>
          -74.006,40.712,0
          -74.005,40.713,0
        </coordinates>
      </LineString>
      <ExtendedData>
        <Data name="oneway">
          <value>yes</value>
        </Data>
        <Data name="maxspeed">
          <value>30</value>
        </Data>
      </ExtendedData>
    </Placemark>
  </Document>
</kml>
```

### Directionality Detection:

- **`oneway=yes`**: Only forward direction required
- **`oneway=no`**: Both directions required (default)
- **No oneway field**: Assumes both directions required

---

## Output Structure

After running the pipeline, you'll get:

```
output/
â”œâ”€â”€ route_map.html         # Interactive HTML map
â”œâ”€â”€ route_data.geojson     # Machine-readable GeoJSON
â””â”€â”€ route_map.svg          # Static SVG image
```

### HTML Map Features:

1. **Base Layer**: OpenStreetMap
2. **Required Segments Layer**: Color-coded by type
3. **Computed Route Layer**: Green path with step numbers
4. **Legend**: Explains colors
5. **Controls**: Toggle layers, zoom, pan

### GeoJSON Structure:

```json
{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {
        "segment_id": "Main_St_001",
        "forward_required": true,
        "backward_required": false,
        "feature_type": "segment"
      },
      "geometry": {
        "type": "LineString",
        "coordinates": [...]
      }
    },
    ...
  ]
}
```

---

## Advanced Usage

### Custom Start Point

```python
pipeline = DRPPPipeline()

# Parse KML first
pipeline.segments = pipeline._parse_kml(kml_file)

# Build graph
pipeline.graph = pipeline._build_graph()

# Solve with custom start
from drpp_core import greedy_route_cluster

result = greedy_route_cluster(
    graph=pipeline.graph,
    required_edges=required_edges,
    segment_indices=list(range(len(required_edges))),
    start_node=(40.7128, -74.0060),  # Custom start coordinates
    use_ondemand=True
)
```

### Only Generate Visualizations

```python
from drpp_visualization import DRPPVisualizer

visualizer = DRPPVisualizer()

# You need segments and route_steps already computed
visualizer.generate_html_map(segments, route_steps, Path('output/map.html'))
visualizer.generate_geojson(segments, route_steps, Path('output/data.geojson'))
visualizer.generate_svg(segments, route_steps, Path('output/map.svg'))
```

### Clustering for Parallel Processing

For very large datasets, use clustering:

```python
from drpp_core import cluster_segments, ClusteringMethod

# Cluster segments geographically
result = cluster_segments(
    segments,
    method=ClusteringMethod.DBSCAN,
    eps_km=2.0,  # 2km radius
    min_samples=3
)

print(f"Created {len(result.clusters)} clusters")
print(f"Noise points: {result.noise_count}")

# Route each cluster separately
for cluster_id, segment_indices in result.clusters.items():
    print(f"Routing cluster {cluster_id} with {len(segment_indices)} segments")
    # ... route cluster ...
```

---

## Troubleshooting

### Issue: "V4 not available"

**Solution**: Install V4 dependencies:
```bash
pip install -r requirements_production.txt
```

### Issue: "Taking forever on large dataset"

**Solution**: Make sure you're using V4 with on-demand mode:
```python
algorithm='v4'  # This auto-enables on-demand for large datasets
```

Or explicitly:
```python
from drpp_core import greedy_route_cluster

result = greedy_route_cluster(
    graph=graph,
    required_edges=edges,
    segment_indices=segments,
    start_node=start,
    use_ondemand=True  # Force on-demand mode
)
```

### Issue: "No segments found in KML"

**Solution**: Check KML format:
1. Must have `<LineString>` placemarks
2. Must have `<coordinates>` element
3. Coordinates must be valid (lon,lat format)

### Issue: "Visualization missing segment IDs"

**Solution**: Make sure your KML has `<name>` tags, or segment IDs will be auto-generated as `seg_00000`, `seg_00001`, etc.

---

## Performance Tips

### For Large Datasets (>1000 segments):

1. âœ… Use V4 greedy algorithm (auto-enables on-demand)
2. âœ… Use DBSCAN clustering to split into smaller groups
3. âœ… Process clusters in parallel
4. âœ… Disable visualization during routing (generate after)

### For Best Quality Routes:

1. âœ… Use RFCS algorithm
2. âœ… Use clustering to manage size
3. âœ… Allow longer computation time

### For Memory Efficiency:

1. âœ… Use V4 (no graph pickling)
2. âœ… Enable on-demand mode
3. âœ… Process in clusters

---

## File Summary

### Core Pipeline:
- `drpp_pipeline.py` - Main pipeline orchestrator
- `drpp_visualization.py` - Visualization module
- `run_drpp_pipeline.py` - Command-line script

### V4 Production Modules:
- `drpp_core/__init__.py` - Public API
- `drpp_core/greedy_router.py` - **Optimized** greedy routing
- `drpp_core/parallel_executor.py` - Parallel processing
- `drpp_core/distance_matrix.py` - Memory-efficient storage
- `drpp_core/clustering.py` - Geographic clustering
- `drpp_core/types.py` - Type definitions
- `drpp_core/logging_config.py` - Structured logging
- `drpp_core/path_reconstruction.py` - Robust path handling
- `drpp_core/profiling.py` - Performance profiling

### Documentation:
- `PIPELINE_GUIDE.md` - This guide
- `V4_INTEGRATION_SUMMARY.md` - V4 integration details
- `PRODUCTION_REFACTOR_GUIDE.md` - Complete V4 API docs

---

## Support

### Documentation:
- This guide: `PIPELINE_GUIDE.md`
- V4 guide: `PRODUCTION_REFACTOR_GUIDE.md`
- Integration: `V4_INTEGRATION_SUMMARY.md`

### Example Code:
- Simple usage: `run_drpp_pipeline.py`
- Advanced usage: `example_production_usage.py`

### Testing:
```bash
# Run unit tests
python -m unittest discover tests -v

# Test on your KML
python run_drpp_pipeline.py your_file.kml v4
```

---

## Changelog

### 2025-11-17 - Pipeline Complete

**Added**:
- âœ… Complete DRPP pipeline (`drpp_pipeline.py`)
- âœ… KML parsing with segment ID extraction
- âœ… Graph building from segments
- âœ… Multi-algorithm solving (RFCS/V4/Greedy/Hungarian)
- âœ… Rich visualization generation
- âœ… Command-line script (`run_drpp_pipeline.py`)
- âœ… This comprehensive guide

**Optimized**:
- âœ… V4 greedy now uses on-demand routing
- âœ… Auto-detects large datasets (>1000 endpoints)
- âœ… 10-100x faster for large datasets

**Fixed**:
- âœ… V4 performance issue with large endpoint sets
- âœ… Memory efficiency for huge datasets

---

**Status**: âœ… Complete and Ready to Use
**Version**: Pipeline v1.0 with V4 Optimization
**Date**: 2025-11-17
